#!/usr/bin/env python3
'''HDF5pp_merge
  Merge an entire HDF5-file into another HDF5-file.

Usage:
  HDF5pp_merge [options] <source> <destination>

Arguments:
  <source>        Source HDF5-file.
  <destination>   Destination HDF5-file.

Options:
  -p, --path=<N>  Root under which to store the source. (default: relative directory of source)
  -v, --verbose   Verbose operations.
  -h, --help      Show help.
      --version   Show version.

(c - MIT) T.W.J. de Geus | tom@geus.me | www.geus.me | github.com/tdegeus/HDF5pp
'''

# ==================================================================================================

import numpy as np
import sys, os, h5py, docopt

# ==================================================================================================

def confirm(message='Proceed [y/n]?\n'):
  r'''
Prompt user for confirmation. The function loops until the user responds with

* 'y' -> True
* 'n' -> False
  '''

  while True:

    # - prompt message, get user's response
    user = input(message)

    # - check response
    if not user                     : print('Please enter y or n.'); continue
    if user not in ['y','Y','n','N']: print('Please enter y or n.'); continue
    if user     in ['y','Y'        ]: return True
    if user     in ['n','N'        ]: return False

# ==================================================================================================

def error(message):
  r'''
Print error message and quit.
  '''

  print(message)

  sys.exit(1)

# ==================================================================================================

def quit(message):
  r'''
Prompt user for confirmation. If the response is negative this function quits the program.
  '''

  if not confirm(message):
    sys.exit(1)

# ==================================================================================================

def abspath(path):
  r'''
Return absolute path.
  '''

  return os.path.normpath(os.path.join('/', path))

# ==================================================================================================

def getdatasets(data, root="/"):
  r'''
Get a list of paths to each dataset in the HDF5-archive.
  '''

  # convert to absolute path
  root = abspath(root)

  # empty list of paths
  datasets = []

  # loop over all fields under the current root
  for name in data[root]:

    # - convert to path
    path = os.path.join(root, name)

    # - current path is a Dataset -> append list, otherwise append list with list of paths
    if isinstance(data[path], h5py.Dataset): datasets += [path]
    else                                   : datasets += getdatasets(data,path)

  # return list of paths
  return datasets

# ==================================================================================================

def verify(data, datasets):
  r'''
Try reading each dataset of a list of datasets. Return a list with only those datasets that can be
successfully opened.
  '''

  # empty list of paths
  out = []

  # loop over list of paths
  for path in datasets:

    # - try reading, move to the next path if reading is unsuccessful
    try   : data[path]
    except: continue

    # - add to output
    out += [path]

  # return list of paths that can be successfully read
  return out

# ==================================================================================================

def exists(data, datasets):
  r'''
Return the first path that exists in the HDF5-archive.
  '''

  for path in datasets:
    if path in data:
      return path

  return False

# ==================================================================================================

def copydatasets(source, dest, source_datasets, dest_datasets=None):
  r'''
Copy all datasets from one HDF5-archive 'source' to another HDF5-archive 'dest'. The datasets
can be renamed by specifying a list of 'dest_datasets' (whose entries should correspond to the
'source_datasets').
  '''

  # make sure that all paths are absolute paths
  source_datasets = [abspath(path) for path in source_datasets]

  # copy the source datasets
  if not dest_datasets: dest_datasets = [path for path in source_datasets]

  # get the group-names from 'source_datasets'
  # - read and filter duplicates
  groups = list(set([os.path.split(path)[0] for path in dest_datasets]))
  # - remove '/'
  groups = [group for group in groups if group != '/']
  # - sort based on depth
  groups = sorted(groups, key=lambda group: (group.count('/'), group))

  # create groups
  for group in groups: dest.create_group(group)

  # copy datasets
  for source_path, dest_path in zip(source_datasets, dest_datasets):

    # - get group name
    group = os.path.split(dest_path)[0]

    # - copy data
    source.copy(source_path, dest[group])

# ==================================================================================================

# parse command-line options
args = docopt.docopt(__doc__,version='0.0.2')

# get root to store the the 'source'
# - read from command-line
root = args['--path']
# - set default
if root is None:
  root = os.path.split(args['<source>'])[0]
# - convert to absolute path
root = abspath(root)

# print progress
if args['--verbose']:
  print('Merging {0:s} -> {1:s}:{2:s}'.format(args['<source>'],args['<destination>'],root))

# open HDF5-files
source = h5py.File(args['<source>'     ], 'r')
dest   = h5py.File(args['<destination>'], 'a')

# get datasets to copy
source_datasets = [abspath(path) for path in verify(source,getdatasets(source))]

# convert to datasets to store
dest_datasets = [os.path.join(root,path[1:]) for path in source_datasets]

# check
if exists(dest, dest_datasets): error('Dataset "{0:s}" exists'.format(exists(dest, dest_datasets)))

# merge
copydatasets(source, dest, source_datasets, dest_datasets)

# close HDF5-files
source.close()
dest  .close()
