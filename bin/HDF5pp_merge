#!/usr/bin/env python3
'''HDF5pp_merge
  Merge an entire HDF5-file into another HDF5-file: copy all datasets from <source> to some root
  in <destination>. The root is based on the path of <source>, as it is specified:

  * without extension (default)
  * only directory name (--dirname)
  * as specified (--ext)
  * apply some regex substitution (--find ... --replace ...)

Usage:
  HDF5pp_merge [options] <source> <destination>

Arguments:
  <source>            Source HDF5-file.
  <destination>       Destination HDF5-file (appended).

Options:
      --ext           Include extension of <source> in root.
      --dirname       Use only directory name of <source> in root.
  -f, --find=ARG      Regex search  to apply to <source>.
  -r, --replace=ARG   Regex replace to apply to <source>.
  -p, --root=ARG      Manually set root.
       --rm           Remove <source> after successful copy.
  -d, --dry-run       Dry run.
      --verbose       Verbose operations.
  -h, --help          Show help.
      --version       Show version.

(c - MIT) T.W.J. de Geus | tom@geus.me | www.geus.me | github.com/tdegeus/HDF5pp
'''

# ==================================================================================================

# temporary fix: suppress warning from h5py
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import sys, os, re, h5py, docopt

# ==================================================================================================

def confirm(message='Proceed [y/n]?\n'):
  r'''
Prompt user for confirmation. The function loops until the user responds with

* 'y' -> True
* 'n' -> False
  '''

  while True:

    # - prompt message, get user's response
    user = input(message)

    # - check response
    if not user                     : print('Please enter y or n.'); continue
    if user not in ['y','Y','n','N']: print('Please enter y or n.'); continue
    if user     in ['y','Y'        ]: return True
    if user     in ['n','N'        ]: return False

# ==================================================================================================

def error(message):
  r'''
Print error message and quit.
  '''

  print(message)

  sys.exit(1)

# ==================================================================================================

def quit(message):
  r'''
Prompt user for confirmation. If the response is negative this function quits the program.
  '''

  if not confirm(message):
    sys.exit(1)

# ==================================================================================================

def check_file(fname):
  r'''
Check if a fail exists, quit otherwise.
  '''

  if not os.path.isfile(fname):
    error('"{0.s}" does not exist'.format(fname))

# ==================================================================================================

def abspath(path):
  r'''
Return absolute path.
  '''

  return os.path.normpath(os.path.join('/', path))

# ==================================================================================================

def getdatasets(data, root="/"):
  r'''
Get a list of paths to each dataset in the HDF5-archive.
  '''

  # convert to absolute path
  root = abspath(root)

  # edge-case: the root it a dataset
  if isinstance(data[root], h5py.Dataset): return [root]

  # empty list of paths
  datasets = []

  # loop over all fields under the current root
  for name in data[root]:

    # - convert to path
    path = os.path.join(root, name)

    # - current path is a Dataset -> append list, otherwise append list with list of paths
    if isinstance(data[path], h5py.Dataset): datasets += [path]
    else                                   : datasets += getdatasets(data,path)

  # return list of paths
  return datasets

# ==================================================================================================

def verify(data, datasets):
  r'''
Try reading each dataset of a list of datasets. Return a list with only those datasets that can be
successfully opened.
  '''

  # empty list of paths
  out = []

  # loop over list of paths
  for path in datasets:

    # - try reading, move to the next path if reading is unsuccessful
    try   : data[path]
    except: continue

    # - add to output
    out += [path]

  # return list of paths that can be successfully read
  return out

# ==================================================================================================

def exists(data, datasets):
  r'''
Return the first path that exists in the HDF5-archive.
  '''

  for path in datasets:
    if path in data:
      return path

  return False

# ==================================================================================================

def copydatasets(source, dest, source_datasets, dest_datasets=None):
  r'''
Copy all datasets from one HDF5-archive 'source' to another HDF5-archive 'dest'. The datasets
can be renamed by specifying a list of 'dest_datasets' (whose entries should correspond to the
'source_datasets').
  '''

  # make sure that all paths are absolute paths
  source_datasets = [abspath(path) for path in source_datasets]

  # copy the source datasets
  if not dest_datasets: dest_datasets = [path for path in source_datasets]

  # get the group-names from 'source_datasets'
  # - read and filter duplicates
  groups = list(set([os.path.split(path)[0] for path in dest_datasets]))
  # - remove '/'
  groups = [group for group in groups if group != '/']
  # - sort based on depth
  groups = sorted(groups, key=lambda group: (group.count('/'), group))

  # create groups
  for group in groups: dest.create_group(group)

  # copy datasets
  for source_path, dest_path in zip(source_datasets, dest_datasets):

    # - get group name
    group = os.path.split(dest_path)[0]

    # - copy data
    source.copy(source_path, dest[group], os.path.split(dest_path)[1])

# ==================================================================================================

# parse command-line options
# --------------------------

args = docopt.docopt(__doc__,version='0.0.2')

# check files
# -----------

# files that are required to exist
check_file(args['<source>'])

# skip files that are the same
if os.path.abspath(args['<source>']) == os.path.abspath(args['<destination>']):

  print('<source> and <destination> are the same, skipping "{0:s}"'.format(args['<source>']))

  sys.exit(0)

# get paths
# ---------

# apply regex to full path
if args['--find'] and args['--replace'] and not args['--root']:

  root = abspath(re.sub(args['--find'], args['--replace'], args['<source>']))

# get explicitly specified path
elif not args['--find'] and not args['--replace'] and args['--root']:

  root = abspath(args['--root'])

# default: path to folder
elif not args['--find'] and not args['--replace'] and not args['--root']:

  if       args['--dirname']: root = abspath(os.path.split   (args['<source>'])[0])
  elif not args['--ext'    ]: root = abspath(os.path.splitext(args['<source>'])[0])
  else                      : root = abspath(                 args['<source>'])[0]

# catch illegal cases
else:

  error('Conflicting options "--find", "--replace", and "--root"')

# dry run
# -------

if args['--dry-run']:

  # print general progress
  print('Merging {0:s} -> {1:s}:{2:s}'.format(args['<source>'],args['<destination>'],root))

  # check that datasets are not already present in the <destination>
  if os.path.isfile(args['<destination>']):

    # - open files
    source = h5py.File(args['<source>'     ], 'r')
    dest   = h5py.File(args['<destination>'], 'r')

    # - get datasets to copy
    source_datasets = [abspath(path) for path in verify(source,getdatasets(source))]

    # - convert to datasets to store
    dest_datasets = [os.path.join(root,path[1:]) for path in source_datasets]

    # - check
    if exists(dest, dest_datasets): error('Dataset "{0:s}" exists'.format(exists(dest, dest_datasets)))

    # - close HDF5-files
    source.close()
    dest  .close()

  # quit
  sys.exit(0)

# verbose
# -------

if args['--verbose']:

  print('Merging {0:s} -> {1:s}:{2:s}'.format(args['<source>'],args['<destination>'],root))

# merge
# -----

# open HDF5-files
source = h5py.File(args['<source>'     ], 'r')
dest   = h5py.File(args['<destination>'], 'a')

# get datasets to copy
source_datasets = [abspath(path) for path in verify(source,getdatasets(source))]

# convert to datasets to store
dest_datasets = [os.path.join(root,path[1:]) for path in source_datasets]

# check
if exists(dest, dest_datasets): error('Dataset "{0:s}" exists'.format(exists(dest, dest_datasets)))

# merge
copydatasets(source, dest, source_datasets, dest_datasets)

# finish
# ------

# close HDF5-files
source.close()
dest  .close()

# remove file
if args['--rm']: os.remove(args['<source>'])
